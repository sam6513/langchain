{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d7d373",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#系统初始化安装包，没有特殊需要，请不要执行本段代码\n",
    "#系统初始化安装包，没有特殊需要，请不要执行本段代码\n",
    "#系统初始化安装包，没有特殊需要，请不要执行本段代码\n",
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install PyPDF2\n",
    "!pip install faiss-cpu\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e692f692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-01 14:28:32--  https://dzhp-app-upload-oss.oss-cn-hangzhou.aliyuncs.com/original_pdf_files/20002.pdf\n",
      "Resolving dzhp-app-upload-oss.oss-cn-hangzhou.aliyuncs.com (dzhp-app-upload-oss.oss-cn-hangzhou.aliyuncs.com)... 118.31.219.215\n",
      "Connecting to dzhp-app-upload-oss.oss-cn-hangzhou.aliyuncs.com (dzhp-app-upload-oss.oss-cn-hangzhou.aliyuncs.com)|118.31.219.215|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 286245 (280K) [application/pdf]\n",
      "Saving to: ‘20002.pdf’\n",
      "\n",
      "20002.pdf           100%[===================>] 279.54K  1.09MB/s    in 0.2s    \n",
      "\n",
      "2023-06-01 14:28:32 (1.09 MB/s) - ‘20002.pdf’ saved [286245/286245]\n",
      "\n",
      "Title:          <4D6963726F736F667420576F7264202D20332D31A1B6BACFB3C9CAF7D6ACB9A4D2B5CEDBC8BECEEFC5C5B7C5B1EAD7BCA1B7A3A8B7A2B2BCB8E5A3A92DD6D5B8E52E646F63>\n",
      "Author:         tangjinlan\n",
      "Creator:        PScript5.dll Version 5.2.2\n",
      "Producer:       Acrobat Distiller 8.0.0 (Windows)\n",
      "CreationDate:   Wed May  6 10:37:08 2015 CST\n",
      "ModDate:        Thu Jun  1 14:26:48 2023 CST\n",
      "Tagged:         no\n",
      "UserProperties: no\n",
      "Suspects:       no\n",
      "Form:           AcroForm\n",
      "JavaScript:     no\n",
      "Pages:          25\n",
      "Encrypted:      no\n",
      "Page size:      595.22 x 842 pts (A4)\n",
      "Page rot:       0\n",
      "File size:      286245 bytes\n",
      "Optimized:      no\n",
      "PDF version:    1.4\n"
     ]
    }
   ],
   "source": [
    "# 查看工作路径https://dzhp-app-upload-oss.oss-cn-hangzhou.aliyuncs.com/original_pdf_files/20000.pdf 大气污染物排放标准\n",
    "\n",
    "!rm -rf 20002.pdf\n",
    "!wget https://dzhp-app-upload-oss.oss-cn-hangzhou.aliyuncs.com/original_pdf_files/20002.pdf -O 20002.pdf\n",
    "!pdfinfo 20002.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6c0cc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] 总共有 25 页\n",
      "[info] 文档总共有 23152 个字符\n",
      "[info] 总共被分割为 46 个文档\n",
      "[info] 索引库名为：review_index_226711\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "#定义openai使用的模型和基本信息\n",
    "llm_model = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo', openai_api_key='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')\n",
    "\n",
    "loader = PyPDFLoader(\"20002.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "#打印基本信息\n",
    "print (f'[info] 总共有 {len(docs)} 页')\n",
    "\n",
    "total = 0\n",
    "for doc in docs:\n",
    "  total += len(doc.page_content)\n",
    "print (f'[info] 文档总共有 {total} 个字符')\n",
    "\n",
    "#按700字拆分文档\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=60)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "print (f'[info] 总共被分割为 {len(split_docs)} 个文档')\n",
    "\n",
    "\n",
    "#开始向量存储部分\n",
    "# OPENAI_API_KEY = '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'\n",
    "openai_api_key = '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'\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "faiss_db = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "\n",
    "index_number=random.randint(100000,999999)\n",
    "\n",
    "persist_directory = 'review'\n",
    "collection_name = 'review_index_' + str(index_number)\n",
    "print('[info] 索引库名为：' + collection_name)\n",
    "\n",
    "faiss_db.save_local(collection_name)\n",
    "vectorstore = FAISS.load_local(collection_name, embeddings)\n",
    "\n",
    "\n",
    "# qa = RetrievalQA.from_llm(llm=llm_model, retriever=vectorstore.as_retriever())\n",
    "\n",
    "\n",
    "# # #从向量数据库中提取3段相关的文本\n",
    "# # query_for_vector = \"合成树脂工业污染物排放标准的适用范围是什么？\"\n",
    "# # docs_after_search = vectorstore.similarity_search(query_for_vector, 3, include_metadata=False)\n",
    "\n",
    "# # #打印向量数据库搜索到的内容\n",
    "# # for doc in docs_after_search:\n",
    "# #     print(doc)\n",
    "    \n",
    "# # Generated examples\n",
    "# from langchain.evaluation.qa import QAGenerateChain\n",
    "# example_gen_chain = QAGenerateChain.from_llm(llm=llm_model)\n",
    "\n",
    "# new_examples = example_gen_chain.apply_and_parse([{\"doc\": t} for t in split_docs[:5]])\n",
    "\n",
    "\n",
    "# new_examples\n",
    "\n",
    "# 问题写在这里\n",
    "# 答案写在这里\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb7be147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'What is the title of the document and what industry does it pertain to?',\n",
       "  'answer': 'The title of the document is \"Emission standard of pollutants for synthetic resin industry\" and it pertains to the synthetic resin industry.'},\n",
       " {'query': 'What is the purpose of section 2 in the document?',\n",
       "  'answer': 'The purpose of section 2 in the document is to list the normative references.'},\n",
       " {'query': 'What is the content of page 6 in the document?',\n",
       "  'answer': 'The content of page 6 in the document is the requirements for controlling the discharge of water pollutants.'},\n",
       " {'query': 'What is the purpose of the standard outlined in this document?',\n",
       "  'answer': 'The purpose of the standard outlined in this document is to establish limits for water and air pollutant emissions, as well as monitoring and management requirements, for synthetic resin (excluding PVC resin) industrial enterprises and their production facilities, in order to protect the environment, prevent pollution, promote technological progress, and ensure sustainable development.'},\n",
       " {'query': 'Who approved the standard and when did it become effective?',\n",
       "  'answer': 'The standard was approved by the Environmental Protection Department on April 3, 2015 and became effective on July 1, 2015.'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "qa = RetrievalQA.from_llm(llm=llm_model, retriever=vectorstore.as_retriever())\n",
    "\n",
    "\n",
    "# #从向量数据库中提取3段相关的文本\n",
    "# query_for_vector = \"合成树脂工业污染物排放标准的适用范围是什么？\"\n",
    "# docs_after_search = vectorstore.similarity_search(query_for_vector, 3, include_metadata=False)\n",
    "\n",
    "# #打印向量数据库搜索到的内容\n",
    "# for doc in docs_after_search:\n",
    "#     print(doc)\n",
    "    \n",
    "# Generated examples\n",
    "from langchain.evaluation.qa import QAGenerateChain\n",
    "example_gen_chain = QAGenerateChain.from_llm(llm=llm_model)\n",
    "\n",
    "new_examples = example_gen_chain.apply_and_parse([{\"doc\": t} for t in split_docs[:5]])\n",
    "\n",
    "\n",
    "new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f2b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
